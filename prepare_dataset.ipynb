{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://mlschool.speechpro.ru/core/results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# !pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from utils import save_obj, load_obj\n",
    "\n",
    "meta_pth = '/media/grigory/Data/ITMO_DATA/data_v_7_stc/meta/meta.txt'\n",
    "train_audio_pth = '/media/grigory/Data/ITMO_DATA/data_v_7_stc/audio'\n",
    "test_audio_pth = '/media/grigory/Data/ITMO_DATA/data_v_7_stc/test'\n",
    "\n",
    "extracted_data = 'data/extracted'\n",
    "if not os.path.exists(extracted_data):\n",
    "    os.mkdir(extracted_data)\n",
    "extracted_train = 'features_labels_train'\n",
    "extracted_test = 'features_labels_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from audio_utils import load_audio, mean_features, cnn_features, seq_features\n",
    "\n",
    "def parse_audio_files(audio_path, limit=None, \n",
    "                      extractor=mean_features,\n",
    "                      stack_first_dim=True,\n",
    "                     **extractor_args):\n",
    "    features = []\n",
    "    names = []\n",
    "    total = len(list(os.scandir(audio_path)))\n",
    "    for i, t in enumerate(tqdm(os.scandir(audio_path), total=total)):\n",
    "        fpth, name = t.path, t.name\n",
    "        # для дебага\n",
    "        if limit and i >= limit: break\n",
    "        try:\n",
    "            ftrz = extractor(fpth, **extractor_args)\n",
    "            if stack_first_dim:\n",
    "                features.append(ftrz)\n",
    "                names.append(name)\n",
    "            else:\n",
    "                features.extend(ftrz)\n",
    "                names.extend([name]*ftrz.shape[0])\n",
    "        except Exception as e:  # да, baseException это плохо\n",
    "            print(e)\n",
    "            print(\"Error processing \" + fpth + \" - skipping\")\n",
    "    return np.array(features), np.array(names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_df = pd.read_csv(meta_pth, sep='\\t', header=None)\n",
    "meta_df.columns = ['name', 'env', 'start_tmstp', 'end_tmstp', 'label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверяем соотвествие между метками в названии и метками в отдельной колонке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'background',\n",
       " 'bags',\n",
       " 'bg',\n",
       " 'd',\n",
       " 'door',\n",
       " 'k',\n",
       " 'keyboard',\n",
       " 'knocking',\n",
       " 'ring',\n",
       " 'speech',\n",
       " 't',\n",
       " 'tool',\n",
       " 'tt'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(pd.Series(os.listdir(train_audio_pth)).apply(lambda x: x.split('_')[0]).value_counts().index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'background',\n",
       " 'bags',\n",
       " 'door',\n",
       " 'keyboard',\n",
       " 'knocking',\n",
       " 'ring',\n",
       " 'speech',\n",
       " 'tool',\n",
       " 'unknown'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(pd.Series(os.listdir(test_audio_pth)).apply(lambda x: x.split('_')[0]).value_counts().index.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "видно, что в тесте, в отличие от трейна, нету \"битых\" меток в именах файлов, так что можно не заморачиваться с  их исправлением в трейне"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Извлекаем признаки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [1:45:54<00:00,  1.78it/s]\n"
     ]
    }
   ],
   "source": [
    "ftrs, names = parse_audio_files(train_audio_pth,\n",
    "                               stack_first_dim=True)\n",
    "labels = meta_df.set_index('name').loc[names]['label'].values\n",
    "# упаковываем в pickle\n",
    "save_obj((ftrs, names, labels), os.path.join(extracted_data, extracted_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 610/610 [06:36<00:00,  1.54it/s]\n"
     ]
    }
   ],
   "source": [
    "ftrs, names = parse_audio_files(test_audio_pth,\n",
    "                               stack_first_dim=True,)\n",
    "# упаковываем в pickle\n",
    "save_obj((ftrs, names), os.path.join(extracted_data, extracted_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "признаки для CNN сети\n",
    "```python3\n",
    "MemoryError\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ftrs, names = parse_audio_files(train_audio_pth, \n",
    "#                                 stack_first_dim=False,\n",
    "#                                 extractor=cnn_features)\n",
    "# save_obj((ftrs, names), os.path.join(extracted_data, extracted_train))\n",
    "\n",
    "# ftrs, names = parse_audio_files(test_audio_pth, \n",
    "#                                 stack_first_dim=False,\n",
    "#                                 extractor=cnn_features)\n",
    "# save_obj((ftrs, names, labels), os.path.join(extracted_data, extracted_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "признаки для LSTM-ки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ftrs, names = parse_audio_files(train_audio_pth, \n",
    "#                                 stack_first_dim=False,\n",
    "#                                 extractor=seq_features)\n",
    "# labels = meta_df.set_index('name').loc[names]['label'].values\n",
    "# save_obj((ftrs, names, labels), os.path.join(extracted_data, extracted_train))\n",
    "\n",
    "# ftrs, names = parse_audio_files(test_audio_pth, \n",
    "#                                 stack_first_dim=False,\n",
    "#                                 extractor=seq_features)\n",
    "# labels = meta_df.set_index('name').loc[names]['label'].values\n",
    "# save_obj((ftrs, names, labels), os.path.join(extracted_data, extracted_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ftr,labels = load_obj(os.path.join(extracted_data, 'features_labels'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import librosa\n",
    "# import librosa.display\n",
    "# %pylab inline\n",
    "# y, sr = librosa.load('/media/grigory/Диск/ITMO_DATA/data_v_7_stc/audio/background_0001.wav', duration=10)\n",
    "# plt.figure(figsize=(15,10))\n",
    "# plt.subplot(3, 1, 1)\n",
    "\n",
    "# librosa.display.waveplot(y, sr=sr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
